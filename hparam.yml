# generator setting
generator_params:
    in_channels: 1
    out_channels: 1
    kernel_size: 3
    layers: 30
    stacks: 3
    residual_channels: 64
    gate_channels: 128
    skip_channels: 64
    aux_channels: 80
    aux_context_window: 2
    dropout: 0.05
    use_weight_norm: true
    upsample_conditional_features: true
    upsample_net: "ConvInUpsampleNetwork"
    upsample_params:
        upsample_scales: [4, 4, 4, 4]

# discriminator setting
discriminator_params:
    in_channels: 1
    out_channels: 1
    kernel_size: 3
    layers: 10
    conv_channels: 64
    nonlinear_activation: "LeakyReLU"
    nonlinear_activation_params:
        negative_slope: 0.2
    bias: true
    use_weight_norm: true

# STFT loss setting
stft_loss_params:
    fft_sizes: [1024, 2048, 512]
    shift_sizes: [120, 240, 50]
    window_lengths: [600, 1200, 240]
    window_type: "hann_window"

# Adversarial loss setting
lambda_adv: 4.0

# feature setting
sampling_rate: 22050
fft_size: 1024
hop_size: 256

# data loader setting
batch_size: 8
batch_max_steps: 19200  # make sure divible by hop_size
pin_memory: true
num_workers: 8
remove_short_samples: false

# optimizer setting
generator_optimizer_params:
    lr: 0.0001
    eps: 0.000001
generator_scheduler_params:
    step_size: 200000
    gamma: 0.5
discriminator_optimizer_params:
    lr: 0.00005
    eps: 0.000001
discriminator_scheduler_params:
    step_size: 200000
    gamma: 0.5
generator_grad_norm: 10
discriminator_grad_norm: 1

# interval setting
discriminator_train_start_steps: 100000
train_max_steps: 400000
save_interval_steps: 5000
eval_interval_steps: 1000
log_interval_steps: 100

# other setting
num_save_intermediate_results: 4
